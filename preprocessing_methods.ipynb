{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Delivery_date Estimated_Receive_date  Weekend_Count  Weekday_Count  \\\n",
      "0    2020-01-04             2020-01-15              4              8   \n",
      "1    2020-01-04             2020-01-11              3              5   \n",
      "2    2020-01-09             2020-01-16              2              6   \n",
      "3    2020-01-13             2020-01-19              2              5   \n",
      "4    2020-01-15             2020-01-22              2              6   \n",
      "\n",
      "   Holiday_Count  Non_Holiday_Count  Covid  \n",
      "0              0                 12      0  \n",
      "1              0                  8      0  \n",
      "2              0                  8      0  \n",
      "3              0                  7      0  \n",
      "4              0                  8      0  \n"
     ]
    }
   ],
   "source": [
    "#Feature Addtion\n",
    "\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "\n",
    "#load the dataset from CSV file contains 2 col: Delivery date - Estimated Receive date\n",
    "date = pd.read_csv('data/date.csv')\n",
    "\n",
    "#convert date columns to datetime format\n",
    "date['Delivery_date'] = pd.to_datetime(date['Delivery_date'], format='%m/%d/%Y')\n",
    "date['Estimated_Receive_date'] = pd.to_datetime(date['Estimated_Receive_date'], format='%m/%d/%Y')\n",
    "\n",
    "#define national holidays for the given period (2020)\n",
    "vn_holidays = holidays.Vietnam(years=2020)  \n",
    "\n",
    "#function to count weekends and weekdays between two dates\n",
    "def count_weekend_weekday(start_date, end_date):\n",
    "    weekend_count = 0\n",
    "    weekday_count = 0\n",
    "    for single_date in pd.date_range(start=start_date, end=end_date):\n",
    "        if single_date.weekday() >= 5:  #sat or sunday\n",
    "            weekend_count += 1\n",
    "        else:\n",
    "            weekday_count += 1\n",
    "    return weekend_count, weekday_count\n",
    "\n",
    "#function to count the number of holidays and non-holidays in the given period\n",
    "def count_holidays(start_date, end_date):\n",
    "    holiday_count = 0\n",
    "    non_holiday_count = 0\n",
    "    for single_date in pd.date_range(start=start_date, end=end_date):\n",
    "        if single_date in vn_holidays:\n",
    "            holiday_count += 1\n",
    "        else:\n",
    "            non_holiday_count += 1\n",
    "    return holiday_count, non_holiday_count\n",
    "\n",
    "# Function to calculate the Covid period (0: No Covid, 1: Covid, 2: Both)\n",
    "def covid_period(start_date, end_date):\n",
    "    period_1_start = pd.to_datetime('01/23/2020', format='%m/%d/%Y')\n",
    "    period_2_start = pd.to_datetime('04/25/2020', format='%m/%d/%Y')\n",
    "    end_date_covid = pd.to_datetime('12/31/2020', format='%m/%d/%Y')\n",
    "\n",
    "    covid_status = 0  #no Covid by default\n",
    "    if start_date <= period_1_start <= end_date or start_date <= period_2_start <= end_date:\n",
    "        covid_status = 1  #covid period\n",
    "    if start_date <= period_1_start and end_date >= period_2_start:\n",
    "        covid_status = 2  #both Covid and no Covid period\n",
    "    return covid_status\n",
    "\n",
    "# Apply the functions to the data frame\n",
    "date['Weekend_Count'], date['Weekday_Count'] = zip(*date.apply(lambda row: count_weekend_weekday(row['Delivery_date'], row['Estimated_Receive_date']), axis=1))\n",
    "date['Holiday_Count'], date['Non_Holiday_Count'] = zip(*date.apply(lambda row: count_holidays(row['Delivery_date'], row['Estimated_Receive_date']), axis=1))\n",
    "date['Covid'] = date.apply(lambda row: covid_period(row['Delivery_date'], row['Estimated_Receive_date']), axis=1)\n",
    "\n",
    "# Save the updated dataframe to file\n",
    "date.to_csv('updated_date_with_features.csv', index=False)\n",
    "\n",
    "# Display the resulting DataFrame with new features\n",
    "print(date.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "synthetic_data = pd.read_csv(\"data/balanced_synthetic_data_scenario3.csv\")\n",
    "feature_df = pd.read_csv(\"data/preprocessed_df_scenario3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# set x to features in the real dataset, y is the label (can change to feature_df for observation on the synthetic feature importance)\n",
    "X = feature_df.drop(columns=['Label'])\n",
    "y = feature_df['Label']\n",
    "\n",
    "#  Train a RandomForestClassifier (with hyperparameter: n_estimators = 100 means 100 dec trees will be build as part of RF ensemble, higher number of trees = higher performance, randomstate = 42 to make the experiment more consistent, ensure the results in every run, control the randomness of the algorithm)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "#  Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "#  Create a DataFrame to display the feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance of Real Data using Random Forest')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the sorted importance table\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features based on Mutual Information (MI) Scores in both datasets:\n",
      "                Feature  MI_synthetic  MI_real\n",
      "           Container_20      0.041351 0.075049\n",
      "          Holiday_Count      0.024054 0.019407\n",
      "     Delivery_lead_time      0.022952 0.143644\n",
      "    Deli_lead_time_late      0.017679 0.091875\n",
      "                  Korea      0.014170 0.095455\n",
      "          Weekend_Count      0.012888 0.060200\n",
      "Deli_date_lateness_late      0.011210 0.144285\n",
      "           Confirm_late      0.010309 0.019601\n",
      "          Weekday_Count      0.010208 0.036871\n",
      "    Estimated_deli_time      0.005940 0.081493\n"
     ]
    }
   ],
   "source": [
    "#MUTUAL INFO\n",
    "\n",
    "#import libraries\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "# synthetic data and real data already defined\n",
    "# drop target variable and apply mutual information calculation on features\n",
    "X_synthetic = synthetic_data.drop(columns=['Label'])\n",
    "y_synthetic = synthetic_data['Label']\n",
    "\n",
    "X_real = feature_df.drop(columns=['Label'])\n",
    "y_real = feature_df['Label']\n",
    "\n",
    "# calculate mutual information for synthetic data\n",
    "mi_synthetic = mutual_info_classif(X_synthetic, y_synthetic)\n",
    "\n",
    "# calculate mutual information for real data\n",
    "mi_real = mutual_info_classif(X_real, y_real)\n",
    "\n",
    "# create DataFrames to hold the feature names and their corresponding MI scores\n",
    "mi_synthetic_df = pd.DataFrame({'Feature': X_synthetic.columns, 'MI_synthetic': mi_synthetic})\n",
    "mi_real_df = pd.DataFrame({'Feature': X_real.columns, 'MI_real': mi_real})\n",
    "\n",
    "# merge  MI dataframes on the Feature column\n",
    "mi_df = pd.merge(mi_synthetic_df, mi_real_df, on='Feature')\n",
    "\n",
    "# remove features where MI is zero in either dataset\n",
    "mi_df = mi_df[(mi_df['MI_synthetic'] > 0) & (mi_df['MI_real'] > 0)]\n",
    "\n",
    "# sort the features by mutual information (higher MI means more important)\n",
    "mi_df = mi_df.sort_values(by=['MI_synthetic', 'MI_real'], ascending=False)\n",
    "# filter features with non-zero MI in both datasets\n",
    "mi_df_non_zero = mi_df[(mi_df['MI_synthetic'] > 0) & (mi_df['MI_real'] > 0)]\n",
    "\n",
    "# sort features by their average MI score\n",
    "mi_df['Average_MI'] = (mi_df['MI_synthetic'] + mi_df['MI_real']) / 2\n",
    "mi_df_sorted = mi_df.sort_values(by='Average_MI', ascending=False)\n",
    "\n",
    "# ensure 10 features: take non-zero MI features first, then fallback to highest MIs\n",
    "top_features = mi_df_non_zero.head(12)\n",
    "if len(top_features) < 10:\n",
    "    remaining_features = mi_df_sorted[~mi_df_sorted['Feature'].isin(top_features['Feature'])]\n",
    "    top_features = pd.concat([top_features, remaining_features.head(10 - len(top_features))])\n",
    "\n",
    "# display the top features and save to file\n",
    "print(\"Top 10 Features based on Mutual Information (MI) Scores in both datasets:\")\n",
    "print(top_features[['Feature', 'MI_synthetic', 'MI_real']].to_string(index=False))\n",
    "top_features.to_csv(\"data/feature_selection.csv\", index=False)\n",
    "#  the top 10 features display\n",
    "top_features = mi_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTE for handling class imbalance, update the class \"0\" equals to class \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.read_csv(\"data/synthetic_data_scenario1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE \n",
    "\n",
    "#import library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#define synthetic or real data path \n",
    "synthetic_data = pd.read_csv(\"data/synthetic_data_scenario1.csv\")\n",
    "#drop target column (Label) for x and Label for y\n",
    "X = synthetic_data.drop('Label', axis=1)  \n",
    "y = synthetic_data['Label']  \n",
    "#smote hyperparameters and train on synthetic data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target variable back into a DataFrame\n",
    "balanced_synthetic_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "balanced_synthetic_data['Label'] = y_resampled  \n",
    "\n",
    "#  balanced_synthetic_data \n",
    "print(balanced_synthetic_data['Label'].value_counts())  \n",
    "# export to file\n",
    "balanced_synthetic_data.to_csv(\"data/balanced_synthetic_data_scenario2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = feature_df.drop('Label', axis=1)  \n",
    "y = feature_df['Label']  \n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target variable back into a DataFrame\n",
    "balanced_feature_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "balanced_feature_df['Label'] = y_resampled  \n",
    "\n",
    "#  balanced_synthetic_data \n",
    "print(balanced_feature_df['Label'].value_counts())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
